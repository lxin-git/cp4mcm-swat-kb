{"componentChunkName":"component---src-pages-labs-high-speed-file-transfer-at-the-speed-of-business-client-and-cp-4-i-mdx","path":"/labs/high-speed-file-transfer-at-the-speed-of-business/client-and-cp4i/","result":{"pageContext":{"frontmatter":{"title":"Aspera Client & CP4I","description":"Think Lab 5352 - Aspera Client & CP4I","tabs":["Prerequisites","CLI","Client & CP4I","Connect & AoC","Node API","Cloud to Cloud","Distribution"]},"relativePagePath":"/labs/high-speed-file-transfer-at-the-speed-of-business/client-and-cp4i.mdx","titleType":"page","MdxNode":{"id":"3a79606f-64ed-50c9-bf80-b86352bce8f3","children":[],"parent":"0e7d2543-465e-5d45-8fb7-3c9e05ab137f","internal":{"content":"---\ntitle: Aspera Client & CP4I\ndescription: Think Lab 5352 - Aspera Client & CP4I\ntabs:\n  [\n    'Prerequisites',\n    'CLI',\n    'Client & CP4I',\n    'Connect & AoC',\n    'Node API',\n    'Cloud to Cloud',\n    'Distribution',\n  ]\n---\n\nexport const Title = () => <span>High Speed File Transfer at the Speed of Business</span>\n\n## Connecting to Cloud Pak for Integration with the Aspera Native Client\n\nYou will now use the Aspera Client GUI to upload a file to a different Aspera Server. In\nthis section of the lab you will be connecting to an Aspera Cluster running in IBM's Cloud\nPak for Integration (CP4I). Aspera in CP4I is a cloud-native microservices based\ndeployment of the Aspera Server built on-top of OpenShift.\n\n![Overview](./images/native-client-overview.png)\n\n## Let's get started\n\n1. Open a new Terminal window by double clicking the Terminal icon on the desktop.\n\n1. Run the following command to open the Aspera Client GUI\n\n   ```bash\n   asperascp\n   ```\n\n   You can minimise the Terminal window once the client has started. You must leave the\n   terminal window open for the life of the Client process.\n\n   ![Native Client Explain](./images/native-client-explain.png)\n\n- The Aspera Client GUI features the local filesystem on the left of the app and the\n  remote filesystem on the right.\n- The `Connections` button allows you to add new Server connections to the Remote\n  Filesystem pane. There are currently two connections configured; the Aspera CP4I Server\n  and the Aspera Demo Server.\n- The `Preferences` button displays client side preferences. If you click this you will\n  see that the current 'Default Target Rate' is set to 100Mbps, the client will not exceed\n  this rate.\n\n> At this point you can understand how the GUI makes downloading from remote filesystems\n> easier... When connected you can easily browse the content on the remote server.\n\n## Upload a file to the Aspera Cluster running in CP4I\n\n1.  Change the local filesystem (left pane) directory to `/home/ibmuser/`\n\n1.  Select 'Aspera CP4I Server' from the remote filesystem (right pane) and select\n    'Connect'.\n\n    The client will make a connection to the Aspera Cluster in CP4I. You are now able to\n    browse the clusters underlying NFS filesystem... it is empty to begin with.\n\n1.  Perform an upload by simply dragging and dropping the file downloaded in section one\n    `100MB` from the left pane to the right.\n\n    You can select the active session from the bottom panel and then click on `Details` in\n    the upper left corner of the window to see the status for the transfer and optionally\n    adjust transfer rates.\n\n    ![Native Client Upload Status](./images/native-client-upload-status.png)\n\n## **Optional**: View the file is in the clusters NFS attached storage\n\n<InlineNotification kind=\"info\">\n  The following steps are optional and only need to be completed if you would like to see\n  for yourself the file that you have just transferred to the clusters NFS filesystem.\n\nYou will do this by getting access to a shell on one of the containers and viewing the\ncontents of the mounted storage.\n\n</InlineNotification>\n\nYou have now successfully uploaded the file to an NFS persistent volume configured in the\nOpenShift cluster. You can confirm this by accessing the container and viewing the mounted\nstorage.\n\n#### Log in the Openshift CLI\n\n1.  Select the `Dashboards - Red Hat OpenShift Container Platform` bookmark in Firefox.\n\n    ![OCP Dashboard Bookmark](./images/prereq-ocp-dashboard.png)\n\n1.  Select Log in with `htpasswd` and use the `admin` credentials already saved in the\n    browser.\n\n    ![htpasswd](./images/prereq-htpasswd.png)\n\n1.  Select `admin` dropdown from the top-right corner and then the `Copy Login Command`\n    button\n\n    <br />\n\n    ![Copy Login Command](./images/prereq-copy-login-command.png)\n\n    <br />\n\n    **Note:** You may be asked to log in again. Use `htpasswd` and the `admin` account\n    again.\n\n1.  Select the `Display Token` hyperlink to revel the API Token information\n\n1.  Copy the content from the `Log in with this token` codebox\n\n    ![Log in with token](./images/prereq-oc-login-command.png)\n\n1.  Minimise Firefox so you can see the Desktop and double click the Terminal app to open\n    a new window.\n1.  Paste and execute the `oc login` command to log into the OpenShift cluster on the CLI.\n\n    ![OC Login](./images/prereq-oc-log-in.png)\n\n1.  Execute a bash prompt in the Aspera Node API container by running\n\n    ```bash\n    oc -it exec aspera-1-aspera-hsts-node-api-56d574bf77-sk5ns -c asperanode -- bash`\n\n    ```\n\n1.  View the NFS mount mounted on `/asperanode` to the cluster by running\n\n    ```bash\n    `df -h`\n    ```\n\n    <br />\n\n    ![NFS Mount](./images/native-client-nfs-mount.png)\n\n1.  List the contents of the mount to confirm the file is now available inside of the\n    cluster:\n\n    ```bash\n    ls -h /asperanode\n    ```\n\n    <br />\n\n    ![NFS Mount Contents](./images/native-client-nfs-mount-contents.png)\n\n1.  Exit the bash prompt\n\n    ```bash\n    exit\n    ```\n\n## Recap\n\nYou have now moved the file that you downloaded from the Aspera Demo server into a\ncontainerised OpenShift environment, other pods can now access this data.\n\nIn a later section you will be using the Aspera API to trigger a transfer that moves this\nfile from the OpenShift cluster to IBM Cloud Object Storage. To do this you require a\nspecial token that allows you access to the storage. Fortunately the token has already\nbeen generated for you and is currently sitting in a bucket in AWS S3 in Toronto. In the\nnext section you will use the browser and the `Aspera Connect Client` to download this key\nfrom S3 bucket in Toronto.\n","type":"Mdx","contentDigest":"e3dcb57ed32840e6375b7bae539ce3ee","counter":188,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Aspera Client & CP4I","description":"Think Lab 5352 - Aspera Client & CP4I","tabs":["Prerequisites","CLI","Client & CP4I","Connect & AoC","Node API","Cloud to Cloud","Distribution"]},"exports":{},"rawBody":"---\ntitle: Aspera Client & CP4I\ndescription: Think Lab 5352 - Aspera Client & CP4I\ntabs:\n  [\n    'Prerequisites',\n    'CLI',\n    'Client & CP4I',\n    'Connect & AoC',\n    'Node API',\n    'Cloud to Cloud',\n    'Distribution',\n  ]\n---\n\nexport const Title = () => <span>High Speed File Transfer at the Speed of Business</span>\n\n## Connecting to Cloud Pak for Integration with the Aspera Native Client\n\nYou will now use the Aspera Client GUI to upload a file to a different Aspera Server. In\nthis section of the lab you will be connecting to an Aspera Cluster running in IBM's Cloud\nPak for Integration (CP4I). Aspera in CP4I is a cloud-native microservices based\ndeployment of the Aspera Server built on-top of OpenShift.\n\n![Overview](./images/native-client-overview.png)\n\n## Let's get started\n\n1. Open a new Terminal window by double clicking the Terminal icon on the desktop.\n\n1. Run the following command to open the Aspera Client GUI\n\n   ```bash\n   asperascp\n   ```\n\n   You can minimise the Terminal window once the client has started. You must leave the\n   terminal window open for the life of the Client process.\n\n   ![Native Client Explain](./images/native-client-explain.png)\n\n- The Aspera Client GUI features the local filesystem on the left of the app and the\n  remote filesystem on the right.\n- The `Connections` button allows you to add new Server connections to the Remote\n  Filesystem pane. There are currently two connections configured; the Aspera CP4I Server\n  and the Aspera Demo Server.\n- The `Preferences` button displays client side preferences. If you click this you will\n  see that the current 'Default Target Rate' is set to 100Mbps, the client will not exceed\n  this rate.\n\n> At this point you can understand how the GUI makes downloading from remote filesystems\n> easier... When connected you can easily browse the content on the remote server.\n\n## Upload a file to the Aspera Cluster running in CP4I\n\n1.  Change the local filesystem (left pane) directory to `/home/ibmuser/`\n\n1.  Select 'Aspera CP4I Server' from the remote filesystem (right pane) and select\n    'Connect'.\n\n    The client will make a connection to the Aspera Cluster in CP4I. You are now able to\n    browse the clusters underlying NFS filesystem... it is empty to begin with.\n\n1.  Perform an upload by simply dragging and dropping the file downloaded in section one\n    `100MB` from the left pane to the right.\n\n    You can select the active session from the bottom panel and then click on `Details` in\n    the upper left corner of the window to see the status for the transfer and optionally\n    adjust transfer rates.\n\n    ![Native Client Upload Status](./images/native-client-upload-status.png)\n\n## **Optional**: View the file is in the clusters NFS attached storage\n\n<InlineNotification kind=\"info\">\n  The following steps are optional and only need to be completed if you would like to see\n  for yourself the file that you have just transferred to the clusters NFS filesystem.\n\nYou will do this by getting access to a shell on one of the containers and viewing the\ncontents of the mounted storage.\n\n</InlineNotification>\n\nYou have now successfully uploaded the file to an NFS persistent volume configured in the\nOpenShift cluster. You can confirm this by accessing the container and viewing the mounted\nstorage.\n\n#### Log in the Openshift CLI\n\n1.  Select the `Dashboards - Red Hat OpenShift Container Platform` bookmark in Firefox.\n\n    ![OCP Dashboard Bookmark](./images/prereq-ocp-dashboard.png)\n\n1.  Select Log in with `htpasswd` and use the `admin` credentials already saved in the\n    browser.\n\n    ![htpasswd](./images/prereq-htpasswd.png)\n\n1.  Select `admin` dropdown from the top-right corner and then the `Copy Login Command`\n    button\n\n    <br />\n\n    ![Copy Login Command](./images/prereq-copy-login-command.png)\n\n    <br />\n\n    **Note:** You may be asked to log in again. Use `htpasswd` and the `admin` account\n    again.\n\n1.  Select the `Display Token` hyperlink to revel the API Token information\n\n1.  Copy the content from the `Log in with this token` codebox\n\n    ![Log in with token](./images/prereq-oc-login-command.png)\n\n1.  Minimise Firefox so you can see the Desktop and double click the Terminal app to open\n    a new window.\n1.  Paste and execute the `oc login` command to log into the OpenShift cluster on the CLI.\n\n    ![OC Login](./images/prereq-oc-log-in.png)\n\n1.  Execute a bash prompt in the Aspera Node API container by running\n\n    ```bash\n    oc -it exec aspera-1-aspera-hsts-node-api-56d574bf77-sk5ns -c asperanode -- bash`\n\n    ```\n\n1.  View the NFS mount mounted on `/asperanode` to the cluster by running\n\n    ```bash\n    `df -h`\n    ```\n\n    <br />\n\n    ![NFS Mount](./images/native-client-nfs-mount.png)\n\n1.  List the contents of the mount to confirm the file is now available inside of the\n    cluster:\n\n    ```bash\n    ls -h /asperanode\n    ```\n\n    <br />\n\n    ![NFS Mount Contents](./images/native-client-nfs-mount-contents.png)\n\n1.  Exit the bash prompt\n\n    ```bash\n    exit\n    ```\n\n## Recap\n\nYou have now moved the file that you downloaded from the Aspera Demo server into a\ncontainerised OpenShift environment, other pods can now access this data.\n\nIn a later section you will be using the Aspera API to trigger a transfer that moves this\nfile from the OpenShift cluster to IBM Cloud Object Storage. To do this you require a\nspecial token that allows you access to the storage. Fortunately the token has already\nbeen generated for you and is currently sitting in a bucket in AWS S3 in Toronto. In the\nnext section you will use the browser and the `Aspera Connect Client` to download this key\nfrom S3 bucket in Toronto.\n","fileAbsolutePath":"/Users/Mark/Documents/GitHub/SWAT2020v3/src/pages/labs/high-speed-file-transfer-at-the-speed-of-business/client-and-cp4i.mdx"}}}}